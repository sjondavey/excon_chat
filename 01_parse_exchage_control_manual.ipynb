{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A notebook to to take the pdf source document and produce a txt version. \n",
    "NOTE: The txt version needs manual intervention to correct for formatting issues.\n",
    "Post the manual preperation of the txt file it is loaded into the data structures that will be used for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import fitz\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import src.valid_index\n",
    "importlib.reload(src.valid_index)\n",
    "from src.valid_index import get_excon_manual_index\n",
    "\n",
    "adla_index = get_excon_manual_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdf_file = \"./pdf/Currency and Exchanges Manual for Authorised Dealers_20230523.pdf\"\n",
    "pdf_file = \"./pdf/Currency and Exchanges Manual for ADLAs_20231013.pdf\"\n",
    "doc = fitz.open(pdf_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    lines = text.split(\"\\n\")\n",
    "    cleaned_lines = []\n",
    "    for line in lines:\n",
    "        if line.strip():  # If the line contains text other than whitespace\n",
    "            line_text = line.strip()\n",
    "            line_text = line_text.replace(\"---oOo---\", \"\")\n",
    "            cleaned_lines.append(line_text)\n",
    "        else:  # If the line is blank\n",
    "            if cleaned_lines and cleaned_lines[-1] != \"\\n\":  \n",
    "                cleaned_lines.append(\"\\n\")\n",
    "    return \" \".join(cleaned_lines).replace(\" \\n \", \"\\n\")\n",
    "    \n",
    "def output_doc_as_text(pdf_doc, start_page = 0, end_page = 0, header_size=80, footer_size=70):\n",
    "    if end_page == 0 or end_page > len(pdf_doc):\n",
    "        end_page = len(pdf_doc)\n",
    "    if end_page < start_page:\n",
    "        print(\"End page before start page! Doing nothing\")\n",
    "    combined_text = ''\n",
    "    for page_number in range(start_page, end_page):\n",
    "        page = pdf_doc[page_number]\n",
    "        tl = page.rect[0], page.rect[1]  # lower-left coordinates\n",
    "        br = page.rect[2], page.rect[3]  # upper-right\n",
    "        rect = fitz.Rect(tl[0], tl[1]+header_size, br[0], br[1]-footer_size)\n",
    "        raw_text = page.get_text('text', clip=rect)\n",
    "\n",
    "        cleaned_text = clean_text(raw_text)\n",
    "        combined_text += cleaned_text\n",
    "    return combined_text\n",
    "\n",
    "\n",
    "def get_indent(line, valid_index):\n",
    "    indent = None\n",
    "    # Check if line starts with any string from exclusion_list\n",
    "    if any(line.startswith(exclusion) for exclusion in valid_index.exclusion_list):\n",
    "        indent = 0\n",
    "    \n",
    "    # Check if line starts with a string matching any regex pattern from excon_index_patterns\n",
    "    if indent is None:\n",
    "        for idx, pattern in enumerate(valid_index.index_patterns):\n",
    "            if re.match(pattern, line):\n",
    "                indent = idx * 4\n",
    "                break\n",
    "    return indent\n",
    "\n",
    "def add_indents(text, valid_index):\n",
    "    previous_indent = 0\n",
    "    lines = text.split(\"\\n\")\n",
    "    modified_lines = []\n",
    "    for line in lines:\n",
    "        indent = get_indent(line, valid_index)\n",
    "        if indent is None:\n",
    "            indent = previous_indent\n",
    "        modified_line = \" \" * indent + line\n",
    "        modified_lines.append(modified_line)\n",
    "        previous_indent = indent\n",
    "    return \"\\n\".join(modified_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output of the this step is to a temporary file because it needs to be reviewed before it can be used. Only once the review is\n",
    "# complete should the file be moved to the ./manual/ folder for later use\n",
    "\n",
    "document_text = output_doc_as_text(doc, start_page = 6)\n",
    "\n",
    "# output_file = \"./tmp/adla_manual_intermediate.txt\"\n",
    "# with open(output_file, 'w', encoding=\"utf-8\") as f:\n",
    "#         f.write(document_text)\n",
    "\n",
    "output_file = \"./tmp/adla_manual.txt\"\n",
    "document_text = add_indents(document_text, adla_index)\n",
    "with open(output_file, 'w', encoding=\"utf-8\") as f:\n",
    "        f.write(document_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you need to manually review the file and make the necessary changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the text file into the data structures to check everything is ok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'E:/Code/pdf/excon/')\n",
    "\n",
    "import importlib\n",
    "import src.file_tools\n",
    "importlib.reload(src.file_tools)\n",
    "from src.file_tools import read_processed_regs_into_dataframe, get_regulation_detail\n",
    "\n",
    "import src.tree_tools\n",
    "importlib.reload(src.tree_tools)\n",
    "from src.tree_tools import build_tree_for_regulation\n",
    "\n",
    "\n",
    "dir_path = './manual/'\n",
    "file_list = []\n",
    "file_list.append('./manual/adla_manual.txt')\n",
    "non_text_labels = ['Table', 'Formula', 'Example', 'Definition']\n",
    "\n",
    "\n",
    "df_adla, non_text = read_processed_regs_into_dataframe(file_list=file_list, valid_index_checker=adla_index, non_text_labels=non_text_labels)\n",
    "tree_adla = build_tree_for_regulation(\"ADLA\", df_adla, valid_index_checker=adla_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting at an particular parent node (can be the tree root or any child), this method splits up the branch into sections where the text does not exceed a certain word_count cap.\n",
    "\n",
    "Initially this is used to set up the base DataFrame using node == root and later it can be used if we want to change the word_limit for a specific piece of regulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_regs_into_chunks(node, df_with_regs, word_limit_per_chunk, index_checker):\n",
    "    node_list=[]\n",
    "    node_list = split_tree(node, df_excon, word_limit_per_chunk, index_checker, node_list)\n",
    "\n",
    "    section_word_count = []\n",
    "    for node in node_list:\n",
    "        #subsection_text = get_full_text_for_node(node.full_node_name, df, False)\n",
    "        subsection_text = get_regulation_detail(node.full_node_name, df_excon, index_checker)\n",
    "        word_count = len(subsection_text.split(' '))\n",
    "        section_word_count.append([node.full_node_name, subsection_text, word_count])\n",
    "\n",
    "    column_names = ['section', 'text', 'word_count']\n",
    "    return pd.DataFrame(section_word_count, columns=column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'split_tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#node = tree_adla.get_node(node_str)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m word_limit_per_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m\n\u001b[1;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43msplit_regs_into_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_adla\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_limit_per_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madla_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[21], line 3\u001b[0m, in \u001b[0;36msplit_regs_into_chunks\u001b[1;34m(node, df_with_regs, word_limit_per_chunk, index_checker)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit_regs_into_chunks\u001b[39m(node, df_with_regs, word_limit_per_chunk, index_checker):\n\u001b[0;32m      2\u001b[0m     node_list\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m----> 3\u001b[0m     node_list \u001b[38;5;241m=\u001b[39m \u001b[43msplit_tree\u001b[49m(node, df_excon, word_limit_per_chunk, index_checker, node_list)\n\u001b[0;32m      5\u001b[0m     section_word_count \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m node_list:\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;66;03m#subsection_text = get_full_text_for_node(node.full_node_name, df, False)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'split_tree' is not defined"
     ]
    }
   ],
   "source": [
    "node = tree_adla.root\n",
    "#node = tree_adla.get_node(node_str)\n",
    "word_limit_per_chunk = 500\n",
    "df = split_regs_into_chunks(node, df_adla, word_limit_per_chunk, adla_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "007219f1a1c0c3993c3211d5a541b1fa109902aadb48cb5499ee55023bf45452"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
